{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(r'C:\\Users\\sunsharp\\Desktop\\幸福感\\happiness_train_complete.csv',encoding='GB2312')\n",
    "df = df.sample(frac=1,replace=False,random_state=11)    #100%无放回抽样，相当于只是打乱原表的行的顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)   #将打乱顺序的表重新编码index\n",
    "df = df[df[\"happiness\"]>0]   #原表中幸福度非正的都是错误数据,可以剔除12条错误数据\n",
    "Y = df[\"happiness\"]    #训练集模型值\n",
    "\n",
    "df[\"survey_month\"] = df[\"survey_time\"].transform(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")   #返回调查月：用空格来切分日期和时间，日期中第1项为月\n",
    "df[\"survey_day\"] = df[\"survey_time\"].transform(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")   #返回调查日\n",
    "df[\"survey_hour\"] = df[\"survey_time\"].transform(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")   #返回调查小时\n",
    "\n",
    "X = df.drop(columns=[\"id\",\"index\",\"happiness\",\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"])   #除了剔除几个序列标号项外，还有三项数据量很小且无关紧要的列被剔除了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.529596410426692\n",
      "0.4588694401246642\n",
      "0.4049296031780146\n",
      "0.4729609100812177\n",
      "0.42949742988784156\n",
      "0.41419104192921996\n",
      "0.5145899764385667\n",
      "0.5068209525824624\n",
      "0.4832195462705235\n",
      "0.5194021788364706\n",
      "0.4714371481916267\n",
      "0.493436253513913\n",
      "0.469570370739654\n",
      "0.49389096489877776\n",
      "0.42483114288314927\n",
      "lightgbm 0.47248289133218624 [0.529596410426692, 0.4588694401246642, 0.4049296031780146, 0.4729609100812177, 0.42949742988784156, 0.41419104192921996, 0.5145899764385667, 0.5068209525824624, 0.4832195462705235, 0.5194021788364706, 0.4714371481916267, 0.493436253513913, 0.469570370739654, 0.49389096489877776, 0.42483114288314927]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split     #分割数据集，用作模型验证\n",
    "from lightgbm.sklearn import LGBMRegressor      #导入lightGDBT\n",
    "from sklearn.metrics import mean_squared_error     #计算均方误差回归损失（残差）\n",
    "from sklearn.externals import joblib             #保存模型\n",
    "from sklearn.model_selection import KFold        #k折交叉验证\n",
    "\n",
    "kfold = KFold(n_splits=15, shuffle = True, random_state= 12)     #要想随机种子起作用，shuffle就得设置为True，代表允许洗牌，但是随机种子会记住你洗牌的方式\n",
    "model = LGBMRegressor(min_child_samples=6,\n",
    "                      colsample_bytree=0.2\n",
    "                     )\n",
    "mse = []\n",
    "i=0\n",
    "for train, test in kfold.split(X):  #返回的是行号\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = Y.iloc[train]\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = Y.iloc[test]\n",
    "    model.fit(X_train,y_train)\n",
    "#     model2.fit(model.predict(X_train,pred_leaf=True),y_train)\n",
    "#     y_pred = model2.predict(model.predict(X=X_test,pred_leaf=True))\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    e = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    mse.append(e)\n",
    "    print(e)\n",
    "    joblib.dump(filename=\"light\"+str(i),value=model)\n",
    "    i+=1\n",
    "print(\"lightgbm\",np.mean(mse),mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.45450514377237855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.4704459080976553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.45398107906457325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.4752842442418985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.44166640422869086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.4740424619970855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.414644665043313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.451792770308976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.47684027202123286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.49329761555264395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.4755900949442348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.4366128914483463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.5073443590751492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.42703606159588203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost 0.4782073499962756\n",
      "xgboost 0.46208608809255575 [0.45450514377237855, 0.4704459080976553, 0.45398107906457325, 0.4752842442418985, 0.44166640422869086, 0.4740424619970855, 0.414644665043313, 0.451792770308976, 0.47684027202123286, 0.49329761555264395, 0.4755900949442348, 0.4366128914483463, 0.5073443590751492, 0.42703606159588203, 0.4782073499962756]\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=15, shuffle = True, random_state= 11)\n",
    "model = XGBRegressor( booster='gbtree', colsample_bylevel=0.1,\n",
    "       colsample_bytree=0.971, gamma=0.11, learning_rate=0.069, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=499,\n",
    "       n_jobs=-1, nthread=50, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1.0)\n",
    "mse = []\n",
    "i = 0\n",
    "for train, test in kfold.split(X):\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = Y.iloc[train]\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = Y.iloc[test]\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    xg_mse = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    mse.append(xg_mse)\n",
    "    print(\"xgboost\",xg_mse)\n",
    "    joblib.dump(filename=\"xg\"+str(i),value=model)\n",
    "    i+=1\n",
    "print(\"xgboost\",np.mean(mse),mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbdt 0.5193542400891656\n",
      "gbdt 0.457108785796664\n",
      "gbdt 0.4034475085214292\n",
      "gbdt 0.45874896150019173\n",
      "gbdt 0.42902520458691024\n",
      "gbdt 0.4257063827144742\n",
      "gbdt 0.5092957572004748\n",
      "gbdt 0.5034686982225933\n",
      "gbdt 0.45383707066431234\n",
      "gbdt 0.5006116667048904\n",
      "gbdt 0.44782351731362824\n",
      "gbdt 0.4993214164890169\n",
      "gbdt 0.457706715741354\n",
      "gbdt 0.47190987561415015\n",
      "gbdt 0.4350515884701965\n",
      "gbdt 0.46482782597529676 [0.5193542400891656, 0.457108785796664, 0.4034475085214292, 0.45874896150019173, 0.42902520458691024, 0.4257063827144742, 0.5092957572004748, 0.5034686982225933, 0.45383707066431234, 0.5006116667048904, 0.44782351731362824, 0.4993214164890169, 0.457706715741354, 0.47190987561415015, 0.4350515884701965]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=15, shuffle = True, random_state= 12)\n",
    "model = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "             learning_rate=0.051, loss='ls', max_depth=4, max_features=10,\n",
    "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "             min_impurity_split=None, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=600, presort='auto', random_state=3,\n",
    "             subsample=0.98, verbose=0, warm_start=False)\n",
    "\n",
    "X.fillna(-8,inplace=True)\n",
    "mse = []\n",
    "i = 0\n",
    "for train, test in kfold.split(X):\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = Y.iloc[train]\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = Y.iloc[test]\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    gbdt_mse = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    mse.append(gbdt_mse)\n",
    "    print(\"gbdt\",gbdt_mse)\n",
    "    joblib.dump(filename=\"gbdt\"+str(i),value=model)\n",
    "    i+=1\n",
    "print(\"gbdt\",np.mean(mse),mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511494983076655\n",
      "0.4507654177881151\n",
      "0.39862736903093465\n",
      "0.45538896187971983\n",
      "0.41616029441930563\n",
      "0.4131051291690357\n",
      "0.4931005414372874\n",
      "0.4909497926521978\n",
      "0.446242701601748\n",
      "0.4880082062209045\n",
      "0.43915188657381216\n",
      "0.4841211707842039\n",
      "0.4592666836838599\n",
      "0.45707235259079404\n",
      "0.422277614068757\n",
      "catboost 0.45504887366515534 [0.511494983076655, 0.4507654177881151, 0.39862736903093465, 0.45538896187971983, 0.41616029441930563, 0.4131051291690357, 0.4931005414372874, 0.4909497926521978, 0.446242701601748, 0.4880082062209045, 0.43915188657381216, 0.4841211707842039, 0.4592666836838599, 0.45707235259079404, 0.422277614068757]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "kfold = KFold(n_splits=15, shuffle = True, random_state= 12)\n",
    "model = CatBoostRegressor(colsample_bylevel=0.1,thread_count=6,silent=True,iterations=800, \n",
    "                          depth=5, \n",
    "                          learning_rate=0.051, \n",
    "                          loss_function='RMSE',\n",
    "                          l2_leaf_reg = 3)\n",
    "mse = []\n",
    "i=0\n",
    "for train, test in kfold.split(X):\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = Y.iloc[train]\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = Y.iloc[test]\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    err = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    mse.append(err)\n",
    "    print(err)\n",
    "    joblib.dump(filename=\"cat\"+str(i),value=model)\n",
    "    i+=1\n",
    "print(\"catboost\",np.mean(mse),mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:35:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.30587093703623275\n",
      "xg mse: 0.3594664784459855\n",
      "gbdt mse: 0.284963304317945\n",
      "lr mse: 0.30953515391789455\n",
      "[16:35:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.2631777330472176\n",
      "xg mse: 0.3090892975232685\n",
      "gbdt mse: 0.24287768592148765\n",
      "lr mse: 0.2646931032760175\n",
      "[16:35:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.3117831180692731\n",
      "xg mse: 0.36448487487557585\n",
      "gbdt mse: 0.2898762005916937\n",
      "lr mse: 0.3144392726049564\n",
      "[16:35:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.3183468139845969\n",
      "xg mse: 0.37212291504245154\n",
      "gbdt mse: 0.28593369769417726\n",
      "lr mse: 0.3170687760731239\n",
      "[16:35:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.29921160798560453\n",
      "xg mse: 0.35301986484474096\n",
      "gbdt mse: 0.2750492383600251\n",
      "lr mse: 0.3014066265211325\n",
      "[16:35:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.276929275845443\n",
      "xg mse: 0.31740095174973676\n",
      "gbdt mse: 0.25817804528978283\n",
      "lr mse: 0.27856564185206567\n",
      "[16:35:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.3238350436099615\n",
      "xg mse: 0.37127795635373706\n",
      "gbdt mse: 0.29892009780316\n",
      "lr mse: 0.323721416893315\n",
      "[16:35:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.29138243466020747\n",
      "xg mse: 0.3289029414071347\n",
      "gbdt mse: 0.26512869295338437\n",
      "lr mse: 0.28876805124391863\n",
      "[16:35:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.28789168994986347\n",
      "xg mse: 0.33871833328434314\n",
      "gbdt mse: 0.2655830463903189\n",
      "lr mse: 0.289769891657565\n",
      "[16:35:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.29627319776519745\n",
      "xg mse: 0.33794355461256664\n",
      "gbdt mse: 0.2723795600221605\n",
      "lr mse: 0.29471899011233993\n",
      "\n",
      "\n",
      "catmse: 0.2974701851953598\n",
      "xgmse: 0.3452427168139541\n",
      "gbdtmse: 0.27388895693441356\n",
      "lrmse: 0.2982686924152329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "[3.36168144 2.89651295 3.65111471]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"happiness_train_complete.csv\",encoding=\"GB2312\")\n",
    "df = df.sample(frac=1,replace=False,random_state=2000)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df = df[df[\"happiness\"]>0]\n",
    "Y = df[\"happiness\"]\n",
    "df[\"survey_month\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "df[\"survey_day\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "df[\"survey_hour\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "X = df.drop(columns=[\"id\",\"index\",\"happiness\",\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"])\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "kfold = KFold(n_splits=10, shuffle = True, random_state= 110)\n",
    "catmse = []\n",
    "lightmse = []\n",
    "xgmse = []\n",
    "gbdtmse = []\n",
    "lrmse = []\n",
    "i = 0\n",
    "for train, test in kfold.split(X):\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = Y.iloc[train]\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = Y.iloc[test]\n",
    "    \n",
    "    cat = joblib.load(filename=\"cat\"+str(i))\n",
    "    light = joblib.load(filename=\"light\"+str(i))\n",
    "    xg = joblib.load(filename=\"xg\"+str(i))\n",
    "    gbdt = joblib.load(filename=\"gbdt\"+str(i))\n",
    "    \n",
    "    catX = cat.predict(X_test)\n",
    "    cat_mse = mean_squared_error(y_true=y_test,y_pred=catX)\n",
    "    print(\"\\ncat mse:\",cat_mse)\n",
    "    catmse.append(cat_mse)\n",
    "    \n",
    "#     X_test2 = X_test.drop(columns=[\"survey_day\"])\n",
    "#     lightX = light.predict(X_test2)\n",
    "#     light_mse = mean_squared_error(y_true=y_test,y_pred=lightX)\n",
    "#     print(\"light mse:\",light_mse)\n",
    "#     lightmse.append(light_mse)\n",
    "    \n",
    "    xgX = xg.predict(X_test)\n",
    "    xg_mse = mean_squared_error(y_true=y_test,y_pred=xgX)\n",
    "    print(\"xg mse:\",xg_mse)\n",
    "    xgmse.append(xg_mse)\n",
    "    \n",
    "    X_test2 = X_test.fillna(-8)\n",
    "    gbdtX = gbdt.predict(X_test2)\n",
    "    gbdt_mse = mean_squared_error(y_true=y_test,y_pred=gbdtX)\n",
    "    print(\"gbdt mse:\",gbdt_mse)\n",
    "    gbdtmse.append(gbdt_mse)\n",
    "    \n",
    "    res = np.c_[catX,xgX,gbdtX]\n",
    "    e = np.array([1/cat_mse,1/xg_mse,1/gbdt_mse])\n",
    "    y_pred = np.sum(res*e,axis=1)/sum(e)\n",
    "    lr_mse = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    print(\"lr mse:\",lr_mse)\n",
    "    lrmse.append(lr_mse)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "print(\"\\n\\ncatmse:\",np.mean(catmse))\n",
    "# print(\"lightmse:\",np.mean(lightmse))\n",
    "print(\"xgmse:\",np.mean(xgmse))\n",
    "print(\"gbdtmse:\",np.mean(gbdtmse))\n",
    "print(\"lrmse:\",np.mean(lrmse))\n",
    "\n",
    "cat = CatBoostRegressor(colsample_bylevel=0.1,thread_count=6,silent=True,iterations=800, \n",
    "                          depth=5, \n",
    "                          learning_rate=0.051, \n",
    "                          loss_function='RMSE',\n",
    "                          l2_leaf_reg = 3)\n",
    "xg = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.1,\n",
    "       colsample_bytree=0.971, gamma=0.11, learning_rate=0.069, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=499,\n",
    "       n_jobs=-1, nthread=50, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1.0)\n",
    "gbdt = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "             learning_rate=0.051, loss='ls', max_depth=4, max_features=10,\n",
    "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "             min_impurity_split=None, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=600, presort='auto', random_state=3,\n",
    "             subsample=0.98, verbose=0, warm_start=False)\n",
    "cat.fit(X,Y)\n",
    "xg.fit(X,Y)\n",
    "gbdt.fit(X.fillna(-8),Y)\n",
    "    \n",
    "df2 = pd.read_csv(\"happiness_test_complete.csv\",encoding=\"GB2312\")\n",
    "df2[\"survey_month\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "df2[\"survey_day\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "df2[\"survey_hour\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "out = df2[[\"id\"]]\n",
    "X = df2.drop(columns=[\"id\",\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"])\n",
    "X2 = X.drop(columns=[\"survey_day\"])\n",
    "catX = cat.predict(X)\n",
    "xgX = xg.predict(X)\n",
    "gbdtX = gbdt.predict(X.fillna(-8))\n",
    "res = np.c_[catX,xgX,gbdtX]\n",
    "e = np.array([1/np.mean(catmse),1/np.mean(xgmse),1/np.mean(gbdtmse)])\n",
    "y_pred = np.sum(res*e,axis=1)/sum(e)\n",
    "out[\"happiness\"] = y_pred\n",
    "out.to_csv(\"happiness_submit.csv\",index=False)\n",
    "print(\"done\")\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat mse: 0.511494983076655\n",
      "light mse: 0.529596410426692\n",
      "xg mse: 0.3949933979705159\n",
      "gbdt mse: 0.5193542400891656\n",
      "[0.15867478 0.13722065 0.5575129  0.14567166]\n",
      "lr mse: 0.44145482254642227\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.4507654177881151\n",
      "light mse: 0.4588694401246642\n",
      "xg mse: 0.34921170255919454\n",
      "gbdt mse: 0.457108785796664\n",
      "[0.17024536 0.16717017 0.51590806 0.15024863]\n",
      "lr mse: 0.3928117875176375\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.39862736903093465\n",
      "light mse: 0.4049296031780146\n",
      "xg mse: 0.3192823411725259\n",
      "gbdt mse: 0.4034475085214292\n",
      "[0.17765501 0.18809797 0.45604505 0.17305861]\n",
      "lr mse: 0.3566463912636784\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.45538896187971983\n",
      "light mse: 0.4729609100812177\n",
      "xg mse: 0.3557698168444744\n",
      "gbdt mse: 0.45874896150019173\n",
      "[0.16917084 0.15349134 0.51379951 0.16701781]\n",
      "lr mse: 0.39880304784807435\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.41616029441930563\n",
      "light mse: 0.42949742988784156\n",
      "xg mse: 0.33401968129637316\n",
      "gbdt mse: 0.42902520458691024\n",
      "[0.19513336 0.17035482 0.47675056 0.15294048]\n",
      "lr mse: 0.37432473065698135\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.4131051291690357\n",
      "light mse: 0.41419104192921996\n",
      "xg mse: 0.3104125039599635\n",
      "gbdt mse: 0.4257063827144742\n",
      "[0.16625809 0.18549715 0.51892823 0.13789193]\n",
      "lr mse: 0.35157885833016633\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.4931005414372874\n",
      "light mse: 0.5145899764385667\n",
      "xg mse: 0.36918234855236065\n",
      "gbdt mse: 0.5092957572004748\n",
      "[0.16236043 0.13623718 0.5844521  0.1171448 ]\n",
      "lr mse: 0.41699470476528655\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.4909497926521978\n",
      "light mse: 0.5068209525824624\n",
      "xg mse: 0.37212283083906955\n",
      "gbdt mse: 0.5034686982225933\n",
      "[0.16052091 0.13418328 0.56597494 0.1332683 ]\n",
      "lr mse: 0.41893460151975587\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.446242701601748\n",
      "light mse: 0.4832195462705235\n",
      "xg mse: 0.33965884645468014\n",
      "gbdt mse: 0.45383707066431234\n",
      "[0.18410041 0.10449091 0.54804764 0.16306882]\n",
      "lr mse: 0.38517832590139994\n",
      "[16:36:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.4880082062209045\n",
      "light mse: 0.5194021788364706\n",
      "xg mse: 0.3719207244168279\n",
      "gbdt mse: 0.5006116667048904\n",
      "[0.1796186  0.10447266 0.5722995  0.14483866]\n",
      "lr mse: 0.4188968471028583\n",
      "[16:36:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.43915188657381216\n",
      "light mse: 0.4714371481916267\n",
      "xg mse: 0.326344872565609\n",
      "gbdt mse: 0.44782351731362824\n",
      "[0.17065693 0.11862049 0.55678536 0.15264698]\n",
      "lr mse: 0.3715289711626289\n",
      "[16:36:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.4841211707842039\n",
      "light mse: 0.493436253513913\n",
      "xg mse: 0.3701659821651882\n",
      "gbdt mse: 0.4993214164890169\n",
      "[0.16711495 0.16641758 0.55083402 0.12706168]\n",
      "lr mse: 0.4137914698571502\n",
      "[16:36:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.4592666836838599\n",
      "light mse: 0.469570370739654\n",
      "xg mse: 0.34916555587475895\n",
      "gbdt mse: 0.457706715741354\n",
      "[0.15168431 0.15097786 0.52577862 0.16138923]\n",
      "lr mse: 0.39290549569879957\n",
      "[16:36:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.45707235259079404\n",
      "light mse: 0.49389096489877776\n",
      "xg mse: 0.3594686242399743\n",
      "gbdt mse: 0.47190987561415015\n",
      "[0.19608758 0.11012768 0.53301232 0.15207207]\n",
      "lr mse: 0.40398487591065413\n",
      "[16:36:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "cat mse: 0.422277614068757\n",
      "light mse: 0.42483114288314927\n",
      "xg mse: 0.31839021940451495\n",
      "gbdt mse: 0.4350515884701965\n",
      "[0.16651389 0.17807505 0.519917   0.13019338]\n",
      "lr mse: 0.36185145019513043\n",
      "\n",
      "catmse: 0.45504887366515534\n",
      "\n",
      "\n",
      "lightmse: 0.47248289133218624\n",
      "xgmse: 0.3493406298877354\n",
      "gbdtmse: 0.46482782597529676\n",
      "lrmse: 0.3933124253517749\n",
      "[16:36:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:36:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsharp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#LR 融合CatBoostRegressor + LightGBM + xgboost + gbdt现有模型\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"happiness_train_complete.csv\",encoding=\"GB2312\")\n",
    "df = df.sample(frac=1,replace=False,random_state=11)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df = df[df[\"happiness\"]>0]\n",
    "Y = df[\"happiness\"]\n",
    "df[\"survey_month\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "df[\"survey_day\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "df[\"survey_hour\"] = df[\"survey_time\"].map(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "X = df.drop(columns=[\"id\",\"index\",\"happiness\",\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"])\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "kfold = KFold(n_splits=15, shuffle = True, random_state= 12)\n",
    "catmse = []\n",
    "lightmse = []\n",
    "xgmse = []\n",
    "gbdtmse = []\n",
    "lrmse = []\n",
    "i = 0\n",
    "for train, test in kfold.split(X):\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = Y.iloc[train]\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = Y.iloc[test]\n",
    "    \n",
    "    cat = joblib.load(filename=\"cat\"+str(i))\n",
    "    light = joblib.load(filename=\"light\"+str(i))\n",
    "    xg = joblib.load(filename=\"xg\"+str(i))\n",
    "    gbdt = joblib.load(filename=\"gbdt\"+str(i))\n",
    "    \n",
    "    catX = cat.predict(X_test)\n",
    "    cat_mse = mean_squared_error(y_true=y_test,y_pred=catX)\n",
    "    print(\"\\ncat mse:\",cat_mse)\n",
    "    catmse.append(cat_mse)\n",
    "\n",
    "    lightX = light.predict(X_test)\n",
    "    light_mse = mean_squared_error(y_true=y_test,y_pred=lightX)\n",
    "    print(\"light mse:\",light_mse)\n",
    "    lightmse.append(light_mse)\n",
    "    \n",
    "    xgX = xg.predict(X_test)\n",
    "    xg_mse = mean_squared_error(y_true=y_test,y_pred=xgX)\n",
    "    print(\"xg mse:\",xg_mse)\n",
    "    xgmse.append(xg_mse)\n",
    "    \n",
    "    gbdtX = gbdt.predict(X_test.fillna(-8))\n",
    "    gbdt_mse = mean_squared_error(y_true=y_test,y_pred=gbdtX)\n",
    "    print(\"gbdt mse:\",gbdt_mse)\n",
    "    gbdtmse.append(gbdt_mse)\n",
    "    \n",
    "    res = np.c_[catX,lightX,xgX,gbdtX]\n",
    "    lr = Ridge(fit_intercept=False, alpha=75)\n",
    "    lr.fit(res,y_test)\n",
    "    print(lr.coef_)\n",
    "\n",
    "    y_pred = lr.predict(res)\n",
    "    lr_mse = mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    print(\"lr mse:\",lr_mse)\n",
    "    lrmse.append(lr_mse)\n",
    "    joblib.dump(filename=\"lr\"+str(i),value=lr)\n",
    "    i+=1\n",
    "    \n",
    "print(\"\\ncatmse:\",np.mean(catmse))\n",
    "print(\"\\n\\nlightmse:\",np.mean(lightmse))\n",
    "print(\"xgmse:\",np.mean(xgmse))\n",
    "print(\"gbdtmse:\",np.mean(gbdtmse))\n",
    "print(\"lrmse:\",np.mean(lrmse))\n",
    "\n",
    "    \n",
    "df2 = pd.read_csv(\"happiness_test_complete.csv\",encoding=\"GB2312\")\n",
    "df2[\"survey_month\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "df2[\"survey_day\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "df2[\"survey_hour\"] = df2[\"survey_time\"].map(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "out = df2[[\"id\"]]\n",
    "X = df2.drop(columns=[\"id\",\"survey_time\",\"edu_other\",\"property_other\",\"invest_other\"])\n",
    "prediction = []\n",
    "for i in range(15):\n",
    "    cat = joblib.load(filename=\"cat\"+str(i))\n",
    "    light = joblib.load(filename=\"light\"+str(i))\n",
    "    xg = joblib.load(filename=\"xg\"+str(i))\n",
    "    gbdt = joblib.load(filename=\"gbdt\"+str(i))\n",
    "    lr = joblib.load(filename=\"lr\"+str(i))\n",
    "    \n",
    "    catX = cat.predict(X)\n",
    "    lightX = light.predict(X)\n",
    "    xgX = xg.predict(X)\n",
    "    gbdtX = gbdt.predict(X.fillna(-8))\n",
    "    res = np.c_[catX,lightX,xgX,gbdtX]\n",
    "    prediction.append(lr.predict(res))\n",
    "    \n",
    "a = np.array(prediction)\n",
    "def cut(arr):\n",
    "    arr2 = []\n",
    "    for x in arr:\n",
    "        if x<1:\n",
    "            arr2.append(1)\n",
    "        elif x>5:\n",
    "            arr2.append(5)\n",
    "        else :\n",
    "            arr2.append(x)\n",
    "    return arr2\n",
    "out[\"happiness\"] = np.mean(np.array(prediction),axis=0)\n",
    "out.to_csv(\"happiness_submit.csv\",index=False)\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "# out[\"happiness\"] = cut(np.sum((1/np.array(lrmse)*a.T),axis=1)/np.sum(1/np.array(lrmse)))\n",
    "# out.to_csv(\"happiness_submit.csv\",index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
